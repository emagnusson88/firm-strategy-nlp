{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b301b084-2382-42c1-9789-d61c4325db26",
   "metadata": {},
   "source": [
    "# Read text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f5b03ad-c69d-4659-874a-ae8a710a97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sat Jul 17 11:41:51 2021\n",
    "\n",
    "@author: Jos Vilier\n",
    "Code to turn .txt files into a bag of words model\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96bbf20-afbc-41f6-8fb0-15fc7988c527",
   "metadata": {},
   "source": [
    "Import text from all annual reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00644391-a735-4c49-b45e-27832d0c814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"Data/Annual reports/Txt\") # list of all file names\n",
    "data = [] # stores all risk management sections as strings\n",
    "\n",
    "# Open all files and append their contents to data\n",
    "for file in files:\n",
    "    with open(\"Data/Annual reports/Txt/\"+file, 'r', encoding = \"utf8\") as txt:\n",
    "        data.append(txt.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf42088a-82f5-4072-bd01-e2049635068e",
   "metadata": {},
   "source": [
    "Generate Bag of Words dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066ae61a-0767-450e-a2db-efee495810b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer() # initialize sklearn's counter\n",
    "word_count = count_vect.fit_transform(data) # and apply to our texts\n",
    "\n",
    "bow = pd.DataFrame.sparse.from_spmatrix(word_count) # Bag Of Word result in a pandas dataframe\n",
    "bow.columns = count_vect.get_feature_names() # update column headers\n",
    "files = [file.split('.')[0] for file in files] # remove extensions\n",
    "bow.index = files # update index to ticker_year format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b3df67-a48f-4b85-99f6-7d07b9a343e5",
   "metadata": {},
   "source": [
    "Export filtered and unfiltered normalized Bag of Words dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ac92c0a-588f-4a1a-9736-03d7e95823ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and save\n",
    "bow_normalized = bow.div(bow.sum(axis=1), axis=0)\n",
    "bow_normalized.to_csv(\"Data/Bag of words/bow_unfiltered.csv\")\n",
    "\n",
    "# Filter on specific keywords\n",
    "keywords = list(pd.read_csv(\"Data/Bag of words/keywords.csv\", header=None)[0])\n",
    "bow_filtered = bow[keywords]\n",
    "bow_filtered_normalized = bow_filtered.div(bow_filtered.sum(axis=1), axis=0)\n",
    "bow_filtered_normalized.to_csv(\"Data/Bag of words/bow_filtered.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
